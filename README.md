# Stroke-prediction

First of all, done some data cleaning. A caveat for using this data set is that it has certain null values. it either can be deleted or replace them with a median value. After that, perform data visualization to understand the underlying relationships and dependencies within the data. Created heatmaps, countplots and histogram for different features of the data set to look for any relationships between the features and the target variable.

After that, split the data into train and test sets. Train and then predict the random forest model on the data set. In the end get the accuracy scores to check the model performance.
